from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from database import fetch_data
from pinecone_util import upsert_vectors

# from pinecone_util import generate_vectors

def chunk_and_store_data(model_name):
    data = fetch_data()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")

    for row in data:
        # Combine relevant fields into a meaningful text
        combined_text = f"""
        CVE ID: {row[1]}
        Description: {row[4]}
        Affected Product: {row[5]}
        Affected Vendor: {row[6]}
        Affected Version: {row[7]}
        Date Published: {row[8]}
        Date Updated: {row[12]}
        State: {row[13]}
        """

        # Use the text_splitter to split the combined text
        chunks = text_splitter.split_text(combined_text)

        vectors = [(f"{row[1]}_{i}", embedding_model.embed_query(chunk)) for i, chunk in enumerate(chunks)]
        
        print("length of vectors %d", len(vectors))
        upsert_vectors(vectors)
    
    return