import os
from transformers import pipeline
from dotenv import load_dotenv

load_dotenv()

def load_model():
    model_name = "meta-llama/Meta-Llama-3.1-8B-Instruct"
    model = pipeline("text-generation", model=model_name, use_auth_token=os.getenv("HUGGINGFACE_TOKEN"))
    return model

model = load_model()

def get_model_response(prompt):
    response = model(prompt, max_length=200, do_sample=True, top_p=0.95, num_return_sequences=1)
    return response[0]['generated_text']
