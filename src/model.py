import os
from transformers import pipeline
from dotenv import load_dotenv

load_dotenv()

def load_model(model_name):
    model = pipeline("text-generation", model=model_name, use_auth_token=os.getenv("HUGGINGFACE_TOKEN"))
    return model


def get_model_response(model_name, prompt):
    model = load_model(model_name)
    response = model(prompt, max_length=200, do_sample=True, top_p=0.95, num_return_sequences=1)
    return response[0]['generated_text']
