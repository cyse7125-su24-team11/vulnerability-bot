import os
from flask import jsonify
from pinecone import Pinecone, ServerlessSpec
from dotenv import load_dotenv
from langchain_huggingface.embeddings import HuggingFaceEmbeddings
# from langchain_pinecone import PineconeVectorStore


load_dotenv()
pinecone=Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
environment=os.getenv("PINECONE_ENVIRONMENT")
index_name = os.getenv("PINECONE_INDEX_NAME")


if index_name not in pinecone.list_indexes().names():
    pinecone.create_index(
        name=index_name,
        dimension=32,
        metric="cosine",
        spec=ServerlessSpec(
            cloud='aws', 
            region='us-east-1'
        ) 
    )
index = pinecone.Index(index_name)

# def generate_vectors(texts, embeddings):
#     vectorstore_from_texts = PineconeVectorStore.from_texts(
#         texts,
#         index_name=index_name,
#         embedding=embeddings
#     )
#     return vectorstore_from_texts


def upsert_vectors(vectors):
    index.upsert(vectors)
    print(index.describe_index_stats())

def query_pinecone(model_name, query, top_k=5):
    embedding_model = HuggingFaceEmbeddings(model_name=model_name)
    query_vector = embedding_model.embed_query(query)
    results = index.query(vector=[query_vector], top_k=top_k, namespace="")

    if results is None:
        return "No results found"

    # Ensure results is a serializable format
    try:
        # If results is a complex object, convert it to a dict or list here
        serialized_results = {"matches": [match.to_dict() for match in results.matches]}
        return serialized_results
    except Exception as e:
        return str(e)





# embeddings = OpenAIEmbeddings()
# embedding_model = HuggingFaceEmbeddings(model_name=model_name)


# pinecone_store = PineconeVectorStore.from_documents(
#     documents= documents,
#     embedding=embeddings,
#     index_name=index_name
# )
 
